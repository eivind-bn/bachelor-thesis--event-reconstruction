{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Modules to read, process and output events.\n",
    "from core.dsl.transformer.mp4_to_sliding_events import Mp4ToSlidingEvents\n",
    "from core.dsl.transformer.mp4_to_stacking_events import Mp4ToStackingEvents\n",
    "from core.dsl.transformer.mp4_to_singular_events import Mp4ToSingularEvents\n",
    "from core.dsl.transformer.frames_by_event_batches import EventBatchToFrames\n",
    "from core.dsl.sink.event_writer import EventWriter\n",
    "from core.dsl.transformer.frames_by_timestamps import FramesByTimestamps\n",
    "from core.dsl.transformer.event_to_intensity_predictor import AsymptoticIntensityPredictor\n",
    "from core.dsl.transformer.batch_throughput_limiter import BSync\n",
    "from core.dsl.source.mp4_reader import Mp4Reader\n",
    "from core.dsl.sink.window import Window\n",
    "from core.dsl.source.events_reader import EventReader\n",
    "from core.dsl.sink.mp4_writer import Mp4Writer\n",
    "from core.dsl.transformer.mp4_to_greyscale import MP4ToGreyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import metavision_core.utils.samples as samples\n",
    "samples.get_sample('driving_sample.raw', 'samples/events/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Metavision SDK utilizes raw/dat files to read events. Let's begin by downloading samples from their website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_event_samples(directory, filetypes):\n",
    "    absolute_path = os.path.abspath(directory)\n",
    "    files = os.listdir(directory)\n",
    "    return {file[:-4]: f'{absolute_path}/{file}' for file in files if file[-4:] in filetypes}\n",
    "\n",
    "# Authentic events from event cameras.\n",
    "event = load_event_samples('samples/events/', ['.raw', '.dat'])\n",
    "\n",
    "# Conventional frame based video not derived from event cameras.\n",
    "mp4 = load_event_samples('samples/mp4/', ['.mp4'])\n",
    "\n",
    "# Conventional video deconstructed to synthetic events.\n",
    "decon = load_event_samples('samples/decon/', ['.raw', '.dat'])\n",
    "\n",
    "# Events reconstructed to regular video.\n",
    "recon = load_event_samples('samples/recon/', ['.mp4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start with something simple, like streaming a regular video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x23ba77f5d00>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the module that will feed the video stream from the filesystem.\n",
    "mp4_in = Mp4Reader(mp4['formula1'])\n",
    "\n",
    "# This window will consume whatever stream of images you provide it, and display it in a separate window.\n",
    "window = Window('formula1 mp4-stream')\n",
    "\n",
    "# Now we combine the input and output module with >> operator.\n",
    "# Note that both modules must have the same transfer datatype to be compatible, i.e (mp4 -> mp4) or (event -> event).\n",
    "# If the datatype were different, such as (event -> mp4) or (mp4 -> event), converters would have to be placed as well.\n",
    "mp4_in >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Video-stream were probably going a bit fast, right? Let's try to synchronize it with the system-clock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<core.dsl.sink.window.Window at 0x1ed7e262e80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The modules are mutable. Never reuse old instances.\n",
    "mp4_in = Mp4Reader(mp4['formula1'])\n",
    "window = Window('Synced formula1 mp4-stream')\n",
    "\n",
    "# This module treat events and frames equal. It simply restricts the number of invocations per second.\n",
    "# You can use this module for both event and frame datatypes. Note that this module is blocking.\n",
    "frame_sync = BSync(batch_per_second=24.0)\n",
    "\n",
    "mp4_in >> frame_sync >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also compute the greyscale version in real-time.\n",
    "This will be important during this thesis in order to have a comparable ground-truth to reconstructed data.\n",
    "Only greyscale information will be reconstructed, so there's no sense comparing it with rgb video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x2273d5d2850>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp4_in = Mp4Reader(mp4['formula1'])\n",
    "\n",
    "# Accepts any frame, and outputs greyscale variant calculated by average method.\n",
    "greyscale_gen = MP4ToGreyscale()\n",
    "window = Window('Synced formula1 mp4-stream')\n",
    "\n",
    "mp4_in >> greyscale_gen >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now lets render raw events instead to better grasp the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x2273d5e3670>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use a dedicated event reader for this purpose.\n",
    "# Each individual event has a timestamp denoting when it was created.\n",
    "# Delta_t denotes the timespan for each event batch.\n",
    "event_in = EventReader(event['driving_sample'], delta_t=1e4)\n",
    "\n",
    "# Simply render events from each batch to a frame. This frame generator is highly influenced by delta_t.\n",
    "# Increasing it will yield more events per frame.\n",
    "batch_frame_generator = EventBatchToFrames()\n",
    "\n",
    "# No explaining needed.\n",
    "window = Window('Frames from event batches.')\n",
    "\n",
    "# Events are read, then converted to frame, lastly the frames are feed to the window.\n",
    "# events -> frames -> void\n",
    "event_in >> batch_frame_generator >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also synchronize events as we previously did with frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x17f935bbf40>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_in = EventReader(event['back6'], delta_t=1e6)\n",
    "batch_frame_generator = EventBatchToFrames()\n",
    "window = Window('Synchronized frames from event batches')\n",
    "\n",
    "# Lets use Bsync (Batch synchronizer)\n",
    "frame_sync = BSync(batch_per_second=30.0)\n",
    "\n",
    "# Events are read, then converted to frame, then synchronized, lastly the frames are feed to the window.\n",
    "# events -> frames -> frames -> void\n",
    "event_in >> batch_frame_generator >> frame_sync >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now instead of generating frames based on batches, let's use another approach, namely the timestamps on the events itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x17f935bb610>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_in = EventReader(event['driving_sample'], delta_t=1e2)\n",
    "window = Window('Raw to frames conversion')\n",
    "\n",
    "# Not influenced by batch sizes and adjustments to delta_t. Create frames based on timestamps instead.\n",
    "# Note that adjusting fps will only influence the video speed, not smoothness.\n",
    "# This is intended behaviour as the algorithm correlates time with the timestamps, not real-time.\n",
    "timestamp_frame_generator = FramesByTimestamps(fps=200)\n",
    "\n",
    "event_in >> timestamp_frame_generator >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To account for real-time playback problem in the cell above, we incorporate a syncing module like previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x227622fe6d0>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_in = EventReader(event['driving_sample'], delta_t=1e6)\n",
    "window = Window('Synced event stream')\n",
    "timestamp_frame_generator = FramesByTimestamps(fps=30)\n",
    "\n",
    "# Accounting for real-time playback.\n",
    "# Note: might not yield correct result due to lagging.\n",
    "frame_sync = BSync(batch_per_second=30.0)\n",
    "\n",
    "event_in >> timestamp_frame_generator >> frame_sync >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now lets try to reconstruct event data in real-time. This algorithm counts events consecutively and based on the individual\n",
    "events' polarity, either increase or decrease the greyscale value of its respective pixel position. Due to information loss in event data,\n",
    "artifacts such as ghosting will occur. This model uses gaussian filters and decaying factors to compensate for that. You may need to adjust the individual parameters through trial and error to find an optimal setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x14d5c504ac0>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_in = EventReader(event['driving_sample'], delta_t=1e4)\n",
    "\n",
    "reconstructor = AsymptoticIntensityPredictor(\n",
    "    gaussian_filter_sigma=0.3,\n",
    "    intensity_decay=0.2,\n",
    "    intensity_impedance=1.0\n",
    ")\n",
    "\n",
    "window = Window('Reconstruction')\n",
    "\n",
    "event_in >> reconstructor >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Only Authentic events have been visualized so far. Problem with reconstructing authentic event data is that we possess no\n",
    "actual ground-truth (correct data correspondence). Luckily, it's way easier to mimic events from regular pictures than vice-versa.\n",
    "We do this by computing pixel intensity gradients from frame to frame. By doing this, we possess something close to actual real data, but most importantly\n",
    "the actual solution to what a proper reconstruction should look like. Some key differences to keep in mind:\n",
    "\n",
    "* Synthetic events typically have lower temporal resolution.\n",
    "* Lower dynamic range.\n",
    "* Less temporal noise.\n",
    "\n",
    "But having actual intensity information can be argued to outweigh these drawbacks for testing purposes.\n",
    "\n",
    "In the following cell, we will deconstruct an authentic conventional rgb video to 'singular' events. 'singular' is not an acknowledged technical term\n",
    "used to describe events, but we introduced it in this thesis to differentiate it from other deconstruction algorithms that we investigated in this thesis. This deconstruction algorithm is probably the best approximation to how actual events work, while the other 2 are fictionary used to investigate better ways to generate events which may lead to less intensity loss. How 'singular events are generated:\n",
    "\n",
    "1. Using pixel intensity information, count how many threshold has been bypassed.\n",
    "2. Compare it to the count of the previous frame. Regardless of intensity difference between the 2 frames, fire only 1 event. If intensity changed by 2 or more\n",
    "   Only 1 event shall be fired. This 'fire 1 event scheme' is one of several reasons to intensity loss in event cameras.\n",
    "3. Set the new frame as the new state.\n",
    "4. Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<core.dsl.sink.window.Window at 0x1ed7e28b790>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp4_in = Mp4Reader(mp4['formula1'])\n",
    "batch_frame_generator = EventBatchToFrames()\n",
    "window = Window('Deconstruction to singular events.')\n",
    "\n",
    "# The deconstructor producing singular events. You may adjust threshold manually here.\n",
    "# This is not possible with most actual event cameras.\n",
    "deconstructor = Mp4ToSingularEvents(threshold=0.1)\n",
    "\n",
    "# Remember that deconstructor outputs event data.\n",
    "# You must generate frames from them before sending it to the window.\n",
    "# frames -> events -> frames -> void\n",
    "mp4_in >> deconstructor >> batch_frame_generator >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the following cell, we demonstrate deconstruction as well, but now we're using 'sliding' events instead.\n",
    "This algorithm woks very similar to the previous one, but have some subtle difference in threshold placement. Note that this algorithm doesn't render events\n",
    "like the prophesee event camera does, but do yield similar result from visual assessment. One benefit of 'sliding' events contra 'singular' events is that compression artefacts from regular videos is less visible. How it works:\n",
    "\n",
    "1. Take a frame and calculate greyscale intensity information. Note no floor-division here.\n",
    "2. Find out which pixel exceeds that pixels current +- a threshold revolving around it. Those that do are an event.\n",
    "3. Register pixel with events as new states, otherwise leave their states as it is.\n",
    "\n",
    "In contrast to singular events algorithms, pixel states are not discrete values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<core.dsl.sink.window.Window at 0x1ed7e28ba90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp4_in = Mp4Reader(mp4['formula1'])\n",
    "batch_frame_generator = EventBatchToFrames()\n",
    "window = Window('Deconstruction to sliding events.')\n",
    "\n",
    "# The deconstructor producing sliding events. You may adjust threshold manually here.\n",
    "# This is not possible with most actual event cameras.\n",
    "deconstructor = Mp4ToSlidingEvents(threshold=0.1)\n",
    "\n",
    "# Remember that deconstructor outputs event data.\n",
    "# You must generate frames from them before sending it to the window.\n",
    "# frames -> events -> frames -> void\n",
    "mp4_in >> deconstructor >> batch_frame_generator >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lastly, we demonstrate 'stacking' events. This event scheme aimed to solve the event-to-intensity problem due to only firing 1 event when the intensity difference\n",
    "where many times higher. This algorithm works exactly like the singular events algorithm, but compensated for larger changes by firing more events. How it works:\n",
    "\n",
    "1. Using pixel intensity information, count how many threshold has been bypassed.\n",
    "2. Compare it to the count of the previous frame. Judging by the discrete difference, fire exactly that many events.\n",
    "3. Set the new frame as the new state.\n",
    "4. Repeat.\n",
    "\n",
    "NB! This algorithm requires much more memory due to larger event yield. If you choose to record the output, be sure to watch the disk usage frequently\n",
    "as the files sizes will be significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mp4_in = Mp4Reader(mp4['formula1'])\n",
    "batch_frame_generator = EventBatchToFrames()\n",
    "window = Window('Deconstruction to stacking events.')\n",
    "\n",
    "# The deconstructor producing stacking events. You may adjust threshold manually here.\n",
    "# This is not possible with most actual event cameras.\n",
    "deconstructor = Mp4ToStackingEvents(threshold=0.07)\n",
    "\n",
    "# Remember that deconstructor outputs event data.\n",
    "# You must generate frames from them before sending it to the window.\n",
    "# frames -> events -> frames -> void\n",
    "mp4_in >> deconstructor >> batch_frame_generator >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we demonstrate mp4 roundtrip reconstruction, i.e. deconstruction of mp4 and reconstruct it back again."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x23b889f79d0>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp4_in = Mp4Reader(mp4['arnold-arm-wrestle'])\n",
    "\n",
    "deconstructor = Mp4ToSlidingEvents(threshold=0.01)\n",
    "\n",
    "reconstructor = AsymptoticIntensityPredictor(\n",
    "    gaussian_filter_sigma=0.5,\n",
    "    intensity_decay=0.05,\n",
    "    intensity_impedance=1.0,\n",
    ")\n",
    "\n",
    "window = Window('Mp4 roundtrip integrity test')\n",
    "\n",
    "\n",
    "mp4_in >> deconstructor >> reconstructor >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we demonstrate event roundtrip deconstruction, i.e. reconstruction of events, and then deconstruction back to events."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x17c198fe190>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_in = EventReader(event['driving_sample'])\n",
    "\n",
    "reconstructor = AsymptoticIntensityPredictor(\n",
    "    gaussian_filter_sigma=0.7,\n",
    "    intensity_decay=0.0,\n",
    "    intensity_impedance=1.0,\n",
    ")\n",
    "\n",
    "deconstructor = Mp4ToSlidingEvents(threshold=0.01, fps=30)\n",
    "\n",
    "batch_frame_generator = EventBatchToFrames()\n",
    "\n",
    "window = Window('Mp4 roundtrip integrity test')\n",
    "\n",
    "\n",
    "event_in >> reconstructor >> deconstructor >> batch_frame_generator >> window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Event deconstruction can be slow and tedious. Use this command line tool record a sample for multiple use.\n",
    "Feel free to cancel the process anytime to preview the recording. Dat files won't be corrupted by this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/10506 frames.\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\mp4_to_dat.py:97\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     93\u001B[0m     mp4_to_dat()\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 97\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\mp4_to_dat.py:93\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     90\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m event_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msliding\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     91\u001B[0m         mp4_in \u001B[38;5;241m>>\u001B[39m Mp4ToSlidingEvents(threshold) \u001B[38;5;241m>>\u001B[39m progress_report \u001B[38;5;241m>>\u001B[39m dat_out\n\u001B[1;32m---> 93\u001B[0m \u001B[43mmp4_to_dat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\mp4_to_dat.py:88\u001B[0m, in \u001B[0;36mmain.<locals>.mp4_to_dat\u001B[1;34m()\u001B[0m\n\u001B[0;32m     85\u001B[0m     mp4_in \u001B[38;5;241m>>\u001B[39m Mp4ToSingularEvents(threshold) \u001B[38;5;241m>>\u001B[39m progress_report \u001B[38;5;241m>>\u001B[39m dat_out\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m event_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstacking\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m---> 88\u001B[0m     \u001B[43mmp4_in\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>>\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mMp4ToStackingEvents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthreshold\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>>\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mprogress_report\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>>\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdat_out\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m event_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msliding\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     91\u001B[0m     mp4_in \u001B[38;5;241m>>\u001B[39m Mp4ToSlidingEvents(threshold) \u001B[38;5;241m>>\u001B[39m progress_report \u001B[38;5;241m>>\u001B[39m dat_out\n",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\core\\dsl\\source\\module.py:34\u001B[0m, in \u001B[0;36mSource.__rshift__\u001B[1;34m(self, consumer)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__rshift__\u001B[39m(\u001B[38;5;28mself\u001B[39m, consumer):\n\u001B[1;32m---> 34\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_data_processed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconsumer\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\core\\dsl\\source\\module.py:28\u001B[0m, in \u001B[0;36mSource.on_data_processed\u001B[1;34m(self, consumer)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mtype\u001B[39m(consumer), EventDispatcher):\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmessage_dispatcher\u001B[38;5;241m.\u001B[39mjoin(consumer\u001B[38;5;241m.\u001B[39mmessage_dispatcher)\n\u001B[1;32m---> 28\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage_dispatcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnotify\u001B[49m\u001B[43m(\u001B[49m\u001B[43mBROADCASTER_JOINED\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m consumer\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\core\\event\\event_broadcaster.py:21\u001B[0m, in \u001B[0;36mEventBroadcaster.notify\u001B[1;34m(self, subject, **kwargs)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_lock\u001B[38;5;241m.\u001B[39madd(subject)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m broadcaster \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnodes:\n\u001B[1;32m---> 21\u001B[0m     \u001B[43mbroadcaster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnotify\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubject\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_lock\u001B[38;5;241m.\u001B[39mremove(subject)\n",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\core\\event\\event_broadcaster.py:17\u001B[0m, in \u001B[0;36mEventBroadcaster.notify\u001B[1;34m(self, subject, **kwargs)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callbacks \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m callbacks:\n\u001B[1;32m---> 17\u001B[0m         \u001B[43mcallback\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_lock\u001B[38;5;241m.\u001B[39madd(subject)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m broadcaster \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnodes:\n",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\core\\dsl\\sink\\event_writer.py:18\u001B[0m, in \u001B[0;36mEventWriter.__init__.<locals>.<lambda>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwidth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmessage_dispatcher\u001B[38;5;241m.\u001B[39msubscribe(CLOSING, \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdat_writer\u001B[38;5;241m.\u001B[39mclose())\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmessage_dispatcher\u001B[38;5;241m.\u001B[39msubscribe(BROADCASTER_JOINED, \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage_dispatcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnotify\u001B[49m\u001B[43m(\u001B[49m\u001B[43mPIPELINE_READY\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\core\\event\\event_broadcaster.py:21\u001B[0m, in \u001B[0;36mEventBroadcaster.notify\u001B[1;34m(self, subject, **kwargs)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_lock\u001B[38;5;241m.\u001B[39madd(subject)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m broadcaster \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnodes:\n\u001B[1;32m---> 21\u001B[0m     \u001B[43mbroadcaster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnotify\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubject\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_lock\u001B[38;5;241m.\u001B[39mremove(subject)\n",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\core\\event\\event_broadcaster.py:21\u001B[0m, in \u001B[0;36mEventBroadcaster.notify\u001B[1;34m(self, subject, **kwargs)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_lock\u001B[38;5;241m.\u001B[39madd(subject)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m broadcaster \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnodes:\n\u001B[1;32m---> 21\u001B[0m     \u001B[43mbroadcaster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnotify\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubject\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_lock\u001B[38;5;241m.\u001B[39mremove(subject)\n",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\core\\event\\event_broadcaster.py:17\u001B[0m, in \u001B[0;36mEventBroadcaster.notify\u001B[1;34m(self, subject, **kwargs)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callbacks \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m callbacks:\n\u001B[1;32m---> 17\u001B[0m         \u001B[43mcallback\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_lock\u001B[38;5;241m.\u001B[39madd(subject)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m broadcaster \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnodes:\n",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\core\\dsl\\source\\mp4_reader.py:44\u001B[0m, in \u001B[0;36mMp4Reader.iterate_frames\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ret:\n\u001B[0;32m     42\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mproperties\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmessage_dispatcher\u001B[38;5;241m.\u001B[39mnotify(CLOSING)\n",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\core\\dsl\\source\\module.py:19\u001B[0m, in \u001B[0;36mSource.on_data_processed.<locals>.new_callback\u001B[1;34m(data, **kwargs)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     18\u001B[0m     old_cb(data, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 19\u001B[0m     \u001B[43mnew_cb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmessage_dispatcher\u001B[38;5;241m.\u001B[39mnotify(CLOSING)\n",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\core\\dsl\\sink\\module.py:25\u001B[0m, in \u001B[0;36mSink.__call__\u001B[1;34m(self, data, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, data, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 25\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\idatt2900-event-reconstruction\\core\\dsl\\transformer\\mp4_to_stacking_events.py:69\u001B[0m, in \u001B[0;36mMp4ToStackingEvents.process_data\u001B[1;34m(self, image, **kwargs)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mold_levels \u001B[38;5;241m=\u001B[39m new_levels\n\u001B[0;32m     68\u001B[0m \u001B[38;5;66;03m# Make record which is how events are stored.\u001B[39;00m\n\u001B[1;32m---> 69\u001B[0m events \u001B[38;5;241m=\u001B[39m \u001B[43mrecords\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfromarrays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevents\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevent_dtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;66;03m# Done. Transfer to next module.\u001B[39;00m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback(events, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\records.py:678\u001B[0m, in \u001B[0;36mfromarrays\u001B[1;34m(arrayList, dtype, shape, formats, names, titles, aligned, byteorder)\u001B[0m\n\u001B[0;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m testshape \u001B[38;5;241m!=\u001B[39m shape:\n\u001B[0;32m    676\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124marray-shape mismatch in array \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 678\u001B[0m     _array[name] \u001B[38;5;241m=\u001B[39m obj\n\u001B[0;32m    680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _array\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "mp4_input_path = mp4['formula1']\n",
    "dat_output_path = './samples/decon/my-formula1-decon.dat'\n",
    "threshold = 0.01\n",
    "event_mode = 'stacking'\n",
    "\n",
    "%run mp4_to_dat.py -i $mp4_input_path -o $dat_output_path -et $threshold -em $event_mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}