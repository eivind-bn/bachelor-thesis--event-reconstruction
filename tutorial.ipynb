{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Modules to read, process and output events.\n",
    "from core.dsl.transformer.mp4_to_sliding_events import Mp4ToSlidingEvents\n",
    "from core.dsl.transformer.mp4_to_stacking_events import Mp4ToStackingEvents\n",
    "from core.dsl.transformer.mp4_to_singular_events import Mp4ToSingularEvents\n",
    "from core.dsl.transformer.frames_by_event_batches import EventBatchToFrames\n",
    "from core.dsl.sink.event_writer import EventWriter\n",
    "from core.dsl.transformer.frames_by_timestamps import FramesByTimestamps\n",
    "from core.dsl.transformer.event_to_intensity_predictor import AsymptoticIntensityPredictor\n",
    "from core.dsl.transformer.batch_throughput_limiter import BSync\n",
    "from core.dsl.source.mp4_reader import Mp4Reader\n",
    "from core.dsl.sink.window import Window\n",
    "from core.dsl.source.events_reader import EventReader\n",
    "from core.dsl.sink.mp4_writer import Mp4Writer\n",
    "from core.dsl.transformer.mp4_to_greyscale import MP4ToGreyscale"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Metavision SDK utilizes raw/dat files to read events. Run the following method you want to download some. Omit valid argument to print available ones."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import metavision_core.utils.samples as samples\n",
    "\n",
    "def run_me_to_download_event_samples():\n",
    "    samples.get_sample(..., 'samples/events/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now lets load the filepath to a dict, so you can refer to them by their name only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_event_samples(directory, filetypes):\n",
    "    absolute_path = os.path.abspath(directory)\n",
    "    files = os.listdir(directory)\n",
    "    return {file[:-4]: f'{absolute_path}/{file}' for file in files if file[-4:] in filetypes}\n",
    "\n",
    "# Authentic events from event cameras.\n",
    "event = load_event_samples('samples/events/', ['.raw', '.dat'])\n",
    "\n",
    "# Conventional frame based video not derived from event cameras.\n",
    "mp4 = load_event_samples('samples/mp4/', ['.mp4'])\n",
    "\n",
    "# Conventional video deconstructed to synthetic events.\n",
    "decon = load_event_samples('samples/decon/', ['.raw', '.dat'])\n",
    "\n",
    "# Events reconstructed to regular video.\n",
    "recon = load_event_samples('samples/recon/', ['.mp4'])\n",
    "\n",
    "# Now we choose a default one. Feel free to alter this variable if you have you own.\n",
    "DEFAULT_MP4 = 'back6'\n",
    "DEFAULT_EVENT = 'back6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start with something simple, like streaming a regular video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x215e84eef70>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the module that will feed the video stream from the filesystem.\n",
    "mp4_in = Mp4Reader(mp4[DEFAULT_MP4])\n",
    "\n",
    "# This window will consume whatever stream of images you provide it, and display it in a separate window.\n",
    "window = Window(f'{DEFAULT_MP4} mp4-stream')\n",
    "\n",
    "# Now we combine the input and output module with >> operator.\n",
    "# Note that both modules must have the same transfer datatype to be compatible, i.e (mp4 -> mp4) or (event -> event).\n",
    "# If the datatype were different, such as (event -> mp4) or (mp4 -> event), converters would have to be placed as well.\n",
    "mp4_in >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Video-stream were probably going a bit fast, right? Let's try to synchronize it with the system-clock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x215e80afac0>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The modules are mutable. Never reuse old instances.\n",
    "mp4_in = Mp4Reader(mp4[DEFAULT_MP4])\n",
    "window = Window(f'Synced {DEFAULT_MP4} mp4-stream')\n",
    "\n",
    "# This module treat events and frames equal. It simply restricts the number of invocations per second.\n",
    "# You can use this module for both event and frame datatypes. Note that this module is blocking.\n",
    "frame_sync = BSync(batch_per_second=24.0)\n",
    "\n",
    "mp4_in >> frame_sync >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also compute the greyscale version in real-time.\n",
    "This will be important during this thesis in order to have a comparable ground-truth to reconstructed data.\n",
    "Only greyscale information will be reconstructed, so there's no sense comparing it with rgb video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x215e809bd30>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp4_in = Mp4Reader(mp4[DEFAULT_MP4])\n",
    "\n",
    "# Accepts any frame, and outputs greyscale variant calculated by average method.\n",
    "greyscale_gen = MP4ToGreyscale()\n",
    "window = Window(f'Synced {DEFAULT_MP4} greyscale mp4-stream')\n",
    "\n",
    "mp4_in >> greyscale_gen >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now lets render raw events instead to better grasp the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x215e83f5fd0>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use a dedicated event reader for this purpose.\n",
    "# Each individual event has a timestamp denoting when it was created.\n",
    "# Delta_t denotes the timespan for each event batch.\n",
    "event_in = EventReader(event[DEFAULT_EVENT], delta_t=1e4)\n",
    "\n",
    "# Simply render events from each batch to a frame. This frame generator is highly influenced by delta_t.\n",
    "# Increasing it will yield more events per frame.\n",
    "batch_frame_generator = EventBatchToFrames()\n",
    "\n",
    "# No explaining needed.\n",
    "window = Window(f'Frames from {DEFAULT_EVENT}-event batches.')\n",
    "\n",
    "# Events are read, then converted to frame, lastly the frames are feed to the window.\n",
    "# events -> frames -> void\n",
    "event_in >> batch_frame_generator >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also synchronize events as we previously did with frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x215e8101e80>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_in = EventReader(event[DEFAULT_EVENT], delta_t=1e6)\n",
    "batch_frame_generator = EventBatchToFrames()\n",
    "window = Window('Synchronized frames from event batches')\n",
    "\n",
    "# Lets use Bsync (Batch synchronizer)\n",
    "frame_sync = BSync(batch_per_second=30.0)\n",
    "\n",
    "# Events are read, then converted to frame, then synchronized, lastly the frames are feed to the window.\n",
    "# events -> frames -> frames -> void\n",
    "event_in >> batch_frame_generator >> frame_sync >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now instead of generating frames based on batches, let's use another approach, namely the timestamps on the events itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x215e8a9f1c0>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_in = EventReader(event[DEFAULT_EVENT], delta_t=1e6)\n",
    "window = Window('Raw to frames conversion')\n",
    "\n",
    "# Not influenced by batch sizes and adjustments to delta_t. Create frames based on timestamps instead.\n",
    "# Note that adjusting fps will only influence the video speed, not smoothness.\n",
    "# This is intended behaviour as the algorithm correlates time with the timestamps, not real-time.\n",
    "timestamp_frame_generator = FramesByTimestamps(fps=24)\n",
    "\n",
    "event_in >> timestamp_frame_generator >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To account for real-time playback problem in the cell above, we incorporate a syncing module like previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x21580bcdb50>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_in = EventReader(event[DEFAULT_EVENT], delta_t=1e6)\n",
    "window = Window('Synced event stream')\n",
    "timestamp_frame_generator = FramesByTimestamps(fps=30)\n",
    "\n",
    "# Accounting for real-time playback.\n",
    "# Note: might not yield correct result due to lagging.\n",
    "frame_sync = BSync(batch_per_second=30.0)\n",
    "\n",
    "event_in >> timestamp_frame_generator >> frame_sync >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now lets try to reconstruct event data in real-time. This algorithm counts events consecutively and based on the individual\n",
    "events' polarity, either increase or decrease the greyscale value of its respective pixel position. Due to information loss in event data,\n",
    "artifacts such as ghosting will occur. This model uses gaussian filters and decaying factors to compensate for that. You may need to adjust the individual parameters through trial and error to find an optimal setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x215e7fbd670>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_in = EventReader(event[DEFAULT_EVENT], delta_t=1e5)\n",
    "\n",
    "reconstructor = AsymptoticIntensityPredictor(\n",
    "    gaussian_filter_sigma=0.0,\n",
    "    intensity_decay=0.0,\n",
    "    intensity_impedance=1.0\n",
    ")\n",
    "\n",
    "window = Window(f'{DEFAULT_EVENT}-reconstruction')\n",
    "\n",
    "event_in >> reconstructor >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Only Authentic events have been visualized so far. Problem with reconstructing authentic event data is that we possess no\n",
    "actual ground-truth (correct data correspondence). Luckily, it's way easier to mimic events from regular pictures than vice-versa.\n",
    "We do this by computing pixel intensity gradients from frame to frame. By doing this, we possess something close to actual real data, but most importantly\n",
    "the actual solution to what a proper reconstruction should look like. Some key differences to keep in mind:\n",
    "\n",
    "* Synthetic events typically have lower temporal resolution.\n",
    "* Lower dynamic range.\n",
    "* Less temporal noise.\n",
    "\n",
    "But having actual intensity information can be argued to outweigh these drawbacks for testing purposes.\n",
    "\n",
    "In the following cell, we will deconstruct an authentic conventional rgb video to 'singular' events. 'singular' is not an acknowledged technical term\n",
    "used to describe events, but we introduced it in this thesis to differentiate it from other deconstruction algorithms that we investigated in this thesis. This deconstruction algorithm is probably the best approximation to how actual events work, while the other 2 are fictionary used to investigate better ways to generate events which may lead to less intensity loss. How 'singular events are generated:\n",
    "\n",
    "1. Using pixel intensity information, count how many threshold has been bypassed.\n",
    "2. Compare it to the count of the previous frame. Regardless of intensity difference between the 2 frames, fire only 1 event. If intensity changed by 2 or more\n",
    "   Only 1 event shall be fired. This 'fire 1 event scheme' is one of several reasons to intensity loss in event cameras.\n",
    "3. Set the new frame as the new state.\n",
    "4. Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x215e81116a0>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp4_in = Mp4Reader(mp4[DEFAULT_MP4])\n",
    "batch_frame_generator = EventBatchToFrames()\n",
    "window = Window(f'Deconstructing {DEFAULT_MP4} to singular events.')\n",
    "\n",
    "# The deconstructor producing singular events. You may adjust threshold manually here.\n",
    "# This is not possible with most actual event cameras.\n",
    "deconstructor = Mp4ToSingularEvents(threshold=0.1)\n",
    "\n",
    "# Remember that deconstructor outputs event data.\n",
    "# You must generate frames from them before sending it to the window.\n",
    "# frames -> events -> frames -> void\n",
    "mp4_in >> deconstructor >> batch_frame_generator >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the following cell, we demonstrate deconstruction as well, but now we're using 'sliding' events instead.\n",
    "This algorithm woks very similar to the previous one, but have some subtle difference in threshold placement. Note that this algorithm doesn't render events\n",
    "like the prophesee event camera does, but do yield similar result from visual assessment. One benefit of 'sliding' events contra 'singular' events is that compression artefacts from regular videos is less visible. How it works:\n",
    "\n",
    "1. Take a frame and calculate greyscale intensity information. Note no floor-division here.\n",
    "2. Find out which pixel exceeds that pixels current +- a threshold revolving around it. Those that do are an event.\n",
    "3. Register pixel with events as new states, otherwise leave their states as it is.\n",
    "\n",
    "In contrast to singular events algorithms, pixel states are not discrete values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x215e80aa880>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp4_in = Mp4Reader(mp4[DEFAULT_MP4])\n",
    "batch_frame_generator = EventBatchToFrames()\n",
    "window = Window(f'Deconstructing {DEFAULT_MP4} to sliding events.')\n",
    "\n",
    "# The deconstructor producing sliding events. You may adjust threshold manually here.\n",
    "# This is not possible with most actual event cameras.\n",
    "deconstructor = Mp4ToSlidingEvents(threshold=0.1)\n",
    "\n",
    "# Remember that deconstructor outputs event data.\n",
    "# You must generate frames from them before sending it to the window.\n",
    "# frames -> events -> frames -> void\n",
    "mp4_in >> deconstructor >> batch_frame_generator >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lastly, we demonstrate 'stacking' events. This event scheme aimed to solve the event-to-intensity problem due to only firing 1 event when the intensity difference\n",
    "where many times higher. This algorithm works exactly like the singular events algorithm, but compensated for larger changes by firing more events. How it works:\n",
    "\n",
    "1. Using pixel intensity information, count how many threshold has been bypassed.\n",
    "2. Compare it to the count of the previous frame. Judging by the discrete difference, fire exactly that many events.\n",
    "3. Set the new frame as the new state.\n",
    "4. Repeat.\n",
    "\n",
    "NB! This algorithm requires much more memory due to larger event yield. If you choose to record the output, be sure to watch the disk usage frequently\n",
    "as the files sizes will be significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x215e809b640>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp4_in = Mp4Reader(mp4[DEFAULT_MP4])\n",
    "batch_frame_generator = EventBatchToFrames()\n",
    "window = Window(f'Deconstructing {DEFAULT_MP4} to stacking events.')\n",
    "\n",
    "# The deconstructor producing stacking events. You may adjust threshold manually here.\n",
    "# This is not possible with most actual event cameras.\n",
    "deconstructor = Mp4ToStackingEvents(threshold=0.07)\n",
    "\n",
    "# Remember that deconstructor outputs event data.\n",
    "# You must generate frames from them before sending it to the window.\n",
    "# frames -> events -> frames -> void\n",
    "mp4_in >> deconstructor >> batch_frame_generator >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we demonstrate mp4 roundtrip reconstruction, i.e. deconstruction of mp4 and reconstruct it back again."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x215e81989a0>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp4_in = Mp4Reader(mp4[DEFAULT_MP4])\n",
    "\n",
    "deconstructor = Mp4ToSlidingEvents(threshold=0.01)\n",
    "\n",
    "reconstructor = AsymptoticIntensityPredictor(\n",
    "    gaussian_filter_sigma=0.5,\n",
    "    intensity_decay=0.05,\n",
    "    intensity_impedance=1.0,\n",
    ")\n",
    "\n",
    "window = Window(f'{DEFAULT_MP4} roundtrip integrity test')\n",
    "\n",
    "\n",
    "mp4_in >> deconstructor >> reconstructor >> window"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we demonstrate event roundtrip deconstruction, i.e. reconstruction of events, and then deconstruction back to events."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<core.dsl.sink.window.Window at 0x215e8a9ffd0>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_in = EventReader(event[DEFAULT_EVENT], delta_t=1e6)\n",
    "\n",
    "reconstructor = AsymptoticIntensityPredictor(\n",
    "    gaussian_filter_sigma=0.7,\n",
    "    intensity_decay=0.0,\n",
    "    intensity_impedance=1.0,\n",
    ")\n",
    "\n",
    "deconstructor = Mp4ToSlidingEvents(threshold=0.1, fps=30)\n",
    "\n",
    "batch_frame_generator = EventBatchToFrames()\n",
    "\n",
    "window = Window(f'{DEFAULT_EVENT} roundtrip integrity test')\n",
    "\n",
    "\n",
    "event_in >> reconstructor >> deconstructor >> batch_frame_generator >> window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Event deconstruction can be slow and tedious. Use this command line tool record a sample for multiple use.\n",
    "Feel free to cancel the process anytime to preview the recording. Dat files won't be corrupted by this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mp4_input_path = mp4[...]\n",
    "dat_output_path = f'./samples/decon/{...}.dat'\n",
    "threshold = 0.01\n",
    "event_mode = 'singular' # Supports {singular, stacking, sliding}\n",
    "\n",
    "%run mp4_to_dat.py -i $mp4_input_path -o $dat_output_path -et $threshold -em $event_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also play dat-files directly by using this command line tool."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To take a snapshot of the recording, press the 'c' button.\n",
      "Saving snapshot to:\n",
      "C:\\Users\\eivin\\Desktop\\idatt2900-event-reconstruction/snapshots\n",
      "Saved: C:\\Users\\eivin\\Desktop\\idatt2900-event-reconstruction/snapshots/back6-raw.png\n",
      "Saved: C:\\Users\\eivin\\Desktop\\idatt2900-event-reconstruction/snapshots/back6-recon.png\n"
     ]
    }
   ],
   "source": [
    "event_input_path = event[DEFAULT_EVENT]\n",
    "delta_t = 10000\n",
    "reconstruct = True\n",
    "gaussian_filter = 0.2\n",
    "intensity_decay = 0.05\n",
    "render_combo = True\n",
    "\n",
    "if reconstruct and render_combo:\n",
    "    %run dat_player.py -i $event_input_path -d $delta_t -r $reconstruct -ga $gaussian_filter -de $intensity_decay -c $render_combo\n",
    "elif reconstruct:\n",
    "    %run dat_player.py -i $event_input_path -d $delta_t -r $reconstruct -ga $gaussian_filter -de $intensity_decay\n",
    "elif render_combo:\n",
    "    %run dat_player.py -i $event_input_path -d $delta_t -ga $gaussian_filter -de $intensity_decay -c $render_combo\n",
    "else:\n",
    "    %run dat_player.py -i $event_input_path -d $delta_t -ga $gaussian_filter -de $intensity_decay"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}